# Toxic Tweets Benchmark

Toxicity Classification NLP Project Group 5 (Jackson Lippert - Emma Wigglesworth - Damien Cheung - Evan Placenis)

Toxic Tweets is a benchmark for models designed to classify toxicity in tweets. 
This benchmark is a single-phase evaluation.

This is a **classification task**.

Our project contains sensitive contents including the following:

- Non Toxic
- Toxicity/Severe Toxicity
- Identity Attacks
- Sexual Harassment
- Insults
- Proafanity including racial slurs
- Threats to people's safety
- Sexually Explicit

Adapted from a template by [Adrien Pavao](https://adrienpavao.com/).

You can download an example submission from the original template here: [sample_code_submission.zip](https://github.com/codalab/competition-examples/blob/master/codabench/mini-automl/sample_code_submission.zip).
